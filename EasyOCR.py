# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SgikwSErPEOrf0AdZgoxQZqRpO4NsxO8
"""

import os
import cv2
import easyocr
import time
import threading
from queue import Queue

# Fix OpenMP error (Intel conflict)
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# Initialize EasyOCR for English (No GPU)
reader = easyocr.Reader(['en'], gpu=False)

# Open webcam
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

if not cap.isOpened():
    print("‚ùå Failed to open webcam.")
    exit()

# Set resolution for better performance
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

print("‚úÖ Webcam started. Show clean printed English text. Press 'q' to quit.")

frame_count = 0
results = []
lock = threading.Lock()
start_time = time.time()

# Create a queue for frame synchronization
frame_queue = Queue(maxsize=5)

# OCR processing function
def process_ocr():
    global results
    while True:
        if not frame_queue.empty():
            # Get the next frame from the queue
            frame = frame_queue.get()
            # Convert frame to grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            small_gray = cv2.resize(gray, (0, 0), fx=0.75, fy=0.75)
            # Perform OCR on the current frame
            raw_results = reader.readtext(small_gray, paragraph=False)

            # Filter results based on confidence threshold (0.2)
            filtered = [r for r in raw_results if r[2] > 0.2]

            with lock:
                results = filtered  # Update the results with the OCR data

            # Debug print OCR results
            if filtered:
                for _, text, conf in filtered:
                    print(f"[OCR] '{text.strip()}' (Confidence: {conf:.2f})")
            else:
                print("[OCR] No confident text detected.")

            frame_queue.task_done()  # Mark the task as done

# Start the OCR processing thread
ocr_thread = threading.Thread(target=process_ocr, daemon=True)
ocr_thread.start()

while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Failed to grab frame.")
        break

    # Add the current frame to the queue for OCR processing
    if not frame_queue.full():
        frame_queue.put(frame)

    # Draw OCR results on the frame
    with lock:
        for bbox, text, conf in results:
            # Scale bounding box coordinates back to original frame size
            top_left = tuple(int(coord / 0.75) for coord in bbox[0])
            bottom_right = tuple(int(coord / 0.75) for coord in bbox[2])

            # Draw bounding box and recognized text
            cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)
            cv2.putText(frame, text.strip(), (top_left[0], top_left[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

    # Show FPS on screen
    elapsed = time.time() - start_time
    fps = frame_count / elapsed if elapsed > 0 else 0
    cv2.putText(frame, f"FPS: {fps:.2f}", (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    # Display the processed frame
    cv2.imshow("üîç Live OCR (Real-Time) - Press 'q' to Quit", frame)
    frame_count += 1

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources and close windows
cap.release()
cv2.destroyAllWindows()